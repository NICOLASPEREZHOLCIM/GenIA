{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3f88dd-0f5e-427e-84ee-8934982300d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bedrock with LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11fde4-4cd9-4040-bb3e-b3756c1cd2af",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ec4d6-a422-485d-b959-504cf982c7d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "%pip install llama-index-llms-bedrock\n",
    "!pip install llama-index\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2afd2039-014d-4b86-907c-e7baf81f6c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "558a9372-0789-414a-a1d7-2976056f2015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import botocore\n",
    "from llama_index.llms.bedrock import Bedrock\n",
    "import ipywidgets as widgets\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from labutils import bedrock, model_formatter, tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60379e6-aa5a-4de9-8010-dfa5fe0f252e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "  Using profile: genaidev\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n",
      "Create new client\n",
      "  Using region: None\n",
      "  Using profile: genaidev\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "bedrock_runtime_client, bedrock_control_client = bedrock.get_bedrock_clients()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7daa1a8-d21a-410c-adbf-b253c2dabf80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reference the Bedrock LLM using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5985d96a-60b8-4aad-a01a-5ccf1688edb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5615e048262f4ad4913cfb2456bde0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select LLM:', layout=Layout(width='300px'), options={'Claude': 'anthropic.claude-v2:1', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropdown = tools.model_selection(bedrock_control_client)\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7401b6f3-e940-4ccc-ac22-979d2ecc538d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the LLM parameters\n",
    "inference_parameters = {'max_tokens_to_sample': 4096,\n",
    "                      \"temperature\": 0.5,\n",
    "                      \"top_k\": 250,\n",
    "                      \"top_p\": 1,\n",
    "                      \"stop_sequences\": [\"\\n\\nHuman\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53b126ab-eaf6-4a71-b9b3-f05a2531c4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the Bedrock interactions LLM object\n",
    "modelId = dropdown.value\n",
    "llm = BedrockLLM(model_id = dropdown.value,\n",
    "                client = bedrock_runtime_client,\n",
    "                model_kwargs = inference_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2678ed-f0d6-444f-9a57-5170dd1952f7",
   "metadata": {},
   "source": [
    "## Create a LangChain custom prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbec103a-97ae-4e9e-9d80-dc20f354a228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a prompt template that has multiple input variables\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"customerServiceManager\", \"customerName\", \"feedbackFromCustomer\"], \n",
    "    template=\"\"\"Human: Create an apology email from the Service Manager {customerServiceManager} to {customerName} in response to the following feedback that was received from the customer: \n",
    "                <customer_feedback>{feedbackFromCustomer}</customer_feedback>\n",
    "            Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variables\n",
    "prompt = multi_var_prompt.format(customerServiceManager=\"Bob\", \n",
    "                                 customerName=\"John Doe\", \n",
    "                                 feedbackFromCustomer=\"\"\"Hello Bob,\n",
    "     I am very disappointed with the recent experience I had when I called your customer support.\n",
    "     I was expecting an immediate call back but it took three days for us to get a call back.\n",
    "     The first suggestion to fix the problem was incorrect. Ultimately the problem was fixed after three days.\n",
    "     We are very unhappy with the response provided and may consider taking our business elsewhere.\n",
    "     \"\"\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269652f-a5b7-40d2-9936-ff2aa8e43dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Print the number of tokens in the prompt (for interest/debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45bdfd5-ce76-42e9-81cd-b0892337d163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt has 121 tokens\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(prompt)\n",
    "print(f\"The prompt has {num_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf31e9-56c0-408f-a652-9e23de446aef",
   "metadata": {},
   "source": [
    "## Invoke the model and print the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1064c57-27a4-48c5-911b-e4f1dfeff122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject: Apology for the poor service experience \n",
      "\n",
      "Dear John,\n",
      "\n",
      "I am writing to sincerely apologize for the poor service you recently received when contacting our customer support team. Based on the feedback you provided, it is clear we did not meet your expectations for a timely response and resolution. \n",
      "\n",
      "I want to personally take responsibility for this situation. Our standard is to provide all customers with a call back within 24 hours, and to promptly resolve any issues. Unfortunately, we failed at both in your case. You have my commitment that we will investigate why this occurred in order to prevent similar experiences going forward.\n",
      "\n",
      "I understand that this situation has caused you significant frustration and inconvenience. As a token of appreciation for your patience and a show of good faith as we work to win back your confidence in our services, I would like to offer you a 25% discount that can be applied to your next purchase with us. \n",
      "\n",
      "We truly value you as a customer, John. I hope you will give us another chance to demonstrate we can meet your expectations for support. Please feel free to contact me directly if you have any other questions or feedback. I will be monitoring this issue closely to ensure we provide you the level of service you deserve.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "Bob\n",
      "Service Manager\n",
      "[Company Name]\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "print(response[response.index('\\n')+1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0088c00-ef1e-48b7-9c0e-050a48bdc056",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Let's try it using Claude v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02da7085-11a8-4653-af1a-13645af4eaef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6be19f13-239b-45f5-b483-ffc328ebcb92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fddeb1528a4b298f6b30a8d2a09d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select LLM:', layout=Layout(width='300px'), options={'Claude': 'anthropic.claude-v2:1', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropdown = tools.model_selection(bedrock_control_client)\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bf5b9a5-4f65-41f3-9a78-a3bfd4af42e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_parameters = {\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da5b473f-91e3-49e9-8141-6ee77b9ba353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatBedrock(\n",
    "            model_id = dropdown.value,\n",
    "            client = bedrock_runtime_client,\n",
    "            model_kwargs = inference_parameters,\n",
    "            streaming = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81a4358f-9775-4518-8df6-30dc38f76ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a customer service manager.\"},\n",
    "    {\"role\": \"human\", \"content\": \"Create an apology email from the Service Manager Bob to John Doe in response to the following feedback that was received from the customer:\\n\\nHello Bob,\\nI am very disappointed with the recent experience I had when I called your customer support.\\nI was expecting an immediate call back but it took three days for us to get a call back.\\nThe first suggestion to fix the problem was incorrect. Ultimately the problem was fixed after three days.\\nWe are very unhappy with the response provided and may consider taking our business elsewhere.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f81a07b7-b531-42e2-b6e9-863df3861142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cfd9719-1f17-4bb5-bb1c-53fede2b064b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a draft of the apology email from the Service Manager Bob to John Doe:\n",
      "\n",
      "Subject: Apology for Unsatisfactory Customer Service Experience\n",
      "\n",
      "Dear John Doe,\n",
      "\n",
      "I am writing to express my sincere apologies for the unsatisfactory experience you had when you recently contacted our customer support. As the Service Manager, I take full responsibility for the issues you faced, and I want to assure you that this is not the level of service we strive to provide.\n",
      "\n",
      "I understand that you were expecting an immediate callback, but it took three days for us to get back to you. I can only imagine how frustrating that must have been. Furthermore, the initial suggestion to fix the problem was incorrect, and it took three days to ultimately resolve the issue. This is simply unacceptable, and I deeply regret the inconvenience and dissatisfaction this has caused you.\n",
      "\n",
      "Please know that we value your business highly, and we are committed to providing you with the best possible customer service experience. I have personally reviewed this incident with the team, and we have taken immediate steps to improve our procedures and ensure that this does not happen again.\n",
      "\n",
      "As a gesture of goodwill, I would like to offer you a [insert appropriate compensation, such as a credit, discount, or free service]. I hope that this will help to regain your trust in our company.\n",
      "\n",
      "If there is anything else I can do to make this right, please do not hesitate to let me know. I am available to discuss this further and address any other concerns you may have.\n",
      "\n",
      "Again, I sincerely apologize for the poor service you received. We value your business and hope to have the opportunity to serve you better in the future.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "Bob\n",
      "Service Manager\n",
      "[Company Name]\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
